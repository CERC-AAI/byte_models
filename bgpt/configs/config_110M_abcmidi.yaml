train_folders:
  - "/network/scratch/m/mina.beiramy/bgpt_shared/data/abc-midi/train"
eval_folders:
  - "/network/scratch/m/mina.beiramy/bgpt_shared/data/abc-midi/validation"
base_dir: "/network/scratch/m/mina.beiramy/bgpt_shared/models/abc-to-midi-20240508"
weights_path: "weights.pth"
pre_weights_path: null
logs_path: "log.txt"
checkpoint_path: "checkpoints"
dataloader_path: "dataloaders"
patch_size: 16
patch_length: 512
byte_num_layers: 3
patch_num_layers: 12
hidden_size: 768
num_epochs: 10
learning_rate: 0.0001
batch_size: 16
accumulation_steps: 1
patch_sampling_batch_size: 0
conversion_mode: "abc->mid"
# load_from_checkpoint: false # Deprecated this into a command-line arg that is False by default. So that there's no need to maintain a config where this is True and a reload config where this is True.
load_from_pre_checkpoint: false
checkpoint_frequency: 10000
logging_frequency: 100
first_launch: true
verbose: false
wandb:
  proj_name: byte_models
  entity: jonathanlimsc-wandb
  mode: online # put 'offline' if you don't want it to upload to WanB server
  name: abc-to-midi
